{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy Experiment .ipynb File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import multiprocessing\n",
    "import timm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cofiguration\n",
    "seed = 42\n",
    "check_point_dir_name = 'mask_gender_classification'\n",
    "\n",
    "data_dir = './dataset/train/images/'\n",
    "train_csv_path = './dataset/train/mask_gender_sheet.csv'\n",
    "save_dir = f'./checkpoints/{check_point_dir_name}'\n",
    "\n",
    "train_b_size = 32\n",
    "valid_b_size = 500\n",
    "epochs = 25\n",
    "print_interval = 200\n",
    "lr = 1e-4\n",
    "model_name = 'efficientnet_b4'\n",
    "num_labels = 6\n",
    "loss_function_name = 'CrossEntropyLoss' # ex FocalLoss, CrossEntropyLoss\n",
    "optimizer_name = 'AdamW'\n",
    "comment = 'For classification Mask, Gender'\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_csv_path)\n",
    "imgs_path = train_df['path'] \n",
    "labels = train_df['mask_gender_class'] # input your label feature\n",
    "stratify_col = train_df['class']\n",
    "\n",
    "train_paths, valid_paths, train_labels, valid_labels = train_test_split(imgs_path, labels,\n",
    "                                                                        train_size=0.7,\n",
    "                                                                        shuffle=True,\n",
    "                                                                        random_state=seed,\n",
    "                                                                        stratify=stratify_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(save_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_args = {\n",
    "'seed' : seed,\n",
    "'train_b_size': train_b_size,\n",
    "'epochs' : epochs,\n",
    "'lr' : 1e-4,\n",
    "'model_name' : model_name,\n",
    "'num_labels' : num_labels,\n",
    "'loss_function_name' : loss_function_name,\n",
    "'optimizer_name' : optimizer_name,\n",
    "'comment' : comment\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_dir, 'config.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(dict_args, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datasets class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainDataset(Dataset):\n",
    "    ## input pd.Series\n",
    "    ## output np.ndarray\n",
    "    ## change dummy, if label_col is 'gender' or 'mask_state'\n",
    "    def __init__(self, img_paths : pd.Series, labels : pd.Series, label_col='class', transforms=None):\n",
    "        self.img_paths = img_paths.to_numpy()\n",
    "        self.transforms = transforms\n",
    "        if label_col == 'gender':\n",
    "            self.labels = pd.get_dummies(labels).to_numpy()\n",
    "        elif label_col == 'mask_state':\n",
    "            self.labels = pd.get_dummies(labels).to_numpy()\n",
    "        else: # age, classes\n",
    "            self.labels = labels.to_numpy()\n",
    "        ## if (False), assert occur\n",
    "        assert self.transforms is not None, 'you must use transforms in Trainset'\n",
    "    \n",
    "    ## return numpy img, label\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        img = np.array(Image.open(img_path))\n",
    "\n",
    "        img = self.transforms(image=img)[\"image\"]\n",
    "        label = self.labels[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = A.Compose([A.Resize(height=224, width=224),\n",
    "                              A.HorizontalFlip(p=0.5),\n",
    "                              A.RandomBrightnessContrast(p=0.5),\n",
    "                              A.GaussianBlur(p=0.5),\n",
    "                              A.GridDistortion(p=0.5),\n",
    "                              A.Rotate(limit=30, p=0.5),\n",
    "                              A.Normalize(mean=(0.56019358,0.52410121,0.501457),\n",
    "                              std=(0.23318603,0.24300033,0.24567522)),\n",
    "                              ToTensorV2()])\n",
    "\n",
    "valid_transforms = A.Compose([A.Resize(height=224, width=224),\n",
    "                              A.Normalize(mean=(0.56019358,0.52410121,0.501457),\n",
    "                              std=(0.23318603,0.24300033,0.24567522)),\n",
    "                              ToTensorV2()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = CustomTrainDataset(train_paths, train_labels, 'class', train_transforms)\n",
    "val_dset = CustomTrainDataset(valid_paths, valid_labels, 'class', valid_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "        train_dset,\n",
    "        batch_size=train_b_size,\n",
    "        num_workers=multiprocessing.cpu_count() // 2,\n",
    "        shuffle=True,\n",
    "        pin_memory=True, ## False https://github.com/jacobgil/pytorch-pruning/issues/16\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "        val_dset,\n",
    "        batch_size=valid_b_size,\n",
    "        num_workers=multiprocessing.cpu_count() // 2,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "        drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for check transform\n",
    "# imgs, labels = next(iter(train_loader))\n",
    "# plt.imshow(make_grid(imgs, normalize=True).permute(1,2,0))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 28 06:23:06 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| N/A   41C    P0    37W / 250W |      4MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resnet10t',\n",
       " 'resnet14t',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet32ts',\n",
       " 'resnet33ts',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50_gn',\n",
       " 'resnet50d',\n",
       " 'resnet51q',\n",
       " 'resnet61q',\n",
       " 'resnet101',\n",
       " 'resnet101d',\n",
       " 'resnet152',\n",
       " 'resnet152d',\n",
       " 'resnet200d',\n",
       " 'resnetaa50',\n",
       " 'resnetblur50',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50',\n",
       " 'resnetv2_50d_evos',\n",
       " 'resnetv2_50d_gn',\n",
       " 'resnetv2_50x1_bit_distilled',\n",
       " 'resnetv2_50x1_bitm',\n",
       " 'resnetv2_50x1_bitm_in21k',\n",
       " 'resnetv2_50x3_bitm',\n",
       " 'resnetv2_50x3_bitm_in21k',\n",
       " 'resnetv2_101',\n",
       " 'resnetv2_101x1_bitm',\n",
       " 'resnetv2_101x1_bitm_in21k',\n",
       " 'resnetv2_101x3_bitm',\n",
       " 'resnetv2_101x3_bitm_in21k',\n",
       " 'resnetv2_152x2_bit_teacher',\n",
       " 'resnetv2_152x2_bit_teacher_384',\n",
       " 'resnetv2_152x2_bitm',\n",
       " 'resnetv2_152x2_bitm_in21k',\n",
       " 'resnetv2_152x4_bitm',\n",
       " 'resnetv2_152x4_bitm_in21k']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models('resnet*',pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(model_name=model_name, pretrained=True, num_classes=num_labels)\n",
    "model.to(device)\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction=self.reduction\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loss_function_name == 'CrossEntropyLoss':\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "elif loss_function_name == 'FocalLoss':\n",
    "    criterion = FocalLoss()\n",
    "else:\n",
    "    raise ValueError(f'not implement Loss function : {loss_function_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you param freeze, not update during training\n",
    "optimizer = None\n",
    "if optimizer_name == 'AdamW':\n",
    "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr) \n",
    "else:\n",
    "    raise ValueError(f'not implement Optimizer : {optimizer_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/25](200/414) || training loss 0.9306 || training accuracy 67.14% || lr 0.0001\n",
      "Epoch[1/25](400/414) || training loss 0.6399 || training accuracy 77.02% || lr 0.0001\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.8826! saving the best model..\n",
      "[Val] f1 : 0.8826, loss: 0.2501, acc: 88.62% || best f1 : 0.8826, best loss: 0.2501, best acc: 88.62%\n",
      "Epoch[2/25](200/414) || training loss 0.2205 || training accuracy 92.33% || lr 0.0001\n",
      "Epoch[2/25](400/414) || training loss 0.2010 || training accuracy 93.14% || lr 0.0001\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.9326! saving the best model..\n",
      "[Val] f1 : 0.9326, loss: 0.1607, acc: 91.90% || best f1 : 0.9326, best loss: 0.1607, best acc: 91.90%\n",
      "Epoch[3/25](200/414) || training loss 0.1347 || training accuracy 95.42% || lr 0.0001\n",
      "Epoch[3/25](400/414) || training loss 0.1332 || training accuracy 95.42% || lr 0.0001\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.9548! saving the best model..\n",
      "[Val] f1 : 0.9548, loss: 0.1139, acc: 93.70% || best f1 : 0.9548, best loss: 0.1139, best acc: 93.70%\n",
      "Epoch[4/25](200/414) || training loss 0.0931 || training accuracy 96.78% || lr 0.0001\n",
      "Epoch[4/25](400/414) || training loss 0.0966 || training accuracy 96.70% || lr 0.0001\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.9650! saving the best model..\n",
      "[Val] f1 : 0.9650, loss: 0.0822, acc: 94.53% || best f1 : 0.9650, best loss: 0.0822, best acc: 94.53%\n",
      "Epoch[5/25](200/414) || training loss 0.0702 || training accuracy 97.72% || lr 0.0001\n",
      "Epoch[5/25](400/414) || training loss 0.0713 || training accuracy 97.59% || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] f1 : 0.9626, loss: 0.0785, acc: 94.64% || best f1 : 0.9650, best loss: 0.0785, best acc: 94.64%\n",
      "Epoch[6/25](200/414) || training loss 0.0500 || training accuracy 98.17% || lr 0.0001\n",
      "Epoch[6/25](400/414) || training loss 0.0518 || training accuracy 98.19% || lr 0.0001\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.9739! saving the best model..\n",
      "[Val] f1 : 0.9739, loss: 0.0597, acc: 95.27% || best f1 : 0.9739, best loss: 0.0597, best acc: 95.27%\n",
      "Epoch[7/25](200/414) || training loss 0.0397 || training accuracy 98.61% || lr 0.0001\n",
      "Epoch[7/25](400/414) || training loss 0.0393 || training accuracy 98.65% || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] f1 : 0.9726, loss: 0.0592, acc: 95.26% || best f1 : 0.9739, best loss: 0.0592, best acc: 95.27%\n",
      "Epoch[8/25](200/414) || training loss 0.0332 || training accuracy 99.03% || lr 0.0001\n",
      "Epoch[8/25](400/414) || training loss 0.0308 || training accuracy 98.98% || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] f1 : 0.9726, loss: 0.0548, acc: 95.31% || best f1 : 0.9739, best loss: 0.0548, best acc: 95.31%\n",
      "Epoch[9/25](200/414) || training loss 0.0346 || training accuracy 98.83% || lr 0.0001\n",
      "Epoch[9/25](400/414) || training loss 0.0304 || training accuracy 98.92% || lr 0.0001\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.9786! saving the best model..\n",
      "[Val] f1 : 0.9786, loss: 0.0484, acc: 95.70% || best f1 : 0.9786, best loss: 0.0484, best acc: 95.70%\n",
      "Epoch[10/25](200/414) || training loss 0.0237 || training accuracy 99.05% || lr 0.0001\n",
      "Epoch[10/25](400/414) || training loss 0.0248 || training accuracy 99.09% || lr 0.0001\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.9787! saving the best model..\n",
      "[Val] f1 : 0.9787, loss: 0.0487, acc: 95.70% || best f1 : 0.9787, best loss: 0.0484, best acc: 95.70%\n",
      "Epoch[11/25](200/414) || training loss 0.0229 || training accuracy 99.20% || lr 0.0001\n",
      "Epoch[11/25](400/414) || training loss 0.0206 || training accuracy 99.33% || lr 0.0001\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.9816! saving the best model..\n",
      "[Val] f1 : 0.9816, loss: 0.0417, acc: 95.82% || best f1 : 0.9816, best loss: 0.0417, best acc: 95.82%\n",
      "Epoch[12/25](200/414) || training loss 0.0179 || training accuracy 99.38% || lr 0.0001\n",
      "Epoch[12/25](400/414) || training loss 0.0167 || training accuracy 99.44% || lr 0.0001\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.9828! saving the best model..\n",
      "[Val] f1 : 0.9828, loss: 0.0398, acc: 95.98% || best f1 : 0.9828, best loss: 0.0398, best acc: 95.98%\n",
      "Epoch[13/25](200/414) || training loss 0.0149 || training accuracy 99.42% || lr 0.0001\n",
      "Epoch[13/25](400/414) || training loss 0.0153 || training accuracy 99.45% || lr 0.0001\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.9842! saving the best model..\n",
      "[Val] f1 : 0.9842, loss: 0.0398, acc: 96.00% || best f1 : 0.9842, best loss: 0.0398, best acc: 96.00%\n",
      "Epoch[14/25](200/414) || training loss 0.0127 || training accuracy 99.69% || lr 0.0001\n",
      "Epoch[14/25](400/414) || training loss 0.0149 || training accuracy 99.56% || lr 0.0001\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.9869! saving the best model..\n",
      "[Val] f1 : 0.9869, loss: 0.0295, acc: 96.28% || best f1 : 0.9869, best loss: 0.0295, best acc: 96.28%\n",
      "Epoch[15/25](200/414) || training loss 0.0118 || training accuracy 99.53% || lr 0.0001\n",
      "Epoch[15/25](400/414) || training loss 0.0114 || training accuracy 99.62% || lr 0.0001\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.9878! saving the best model..\n",
      "[Val] f1 : 0.9878, loss: 0.0319, acc: 96.17% || best f1 : 0.9878, best loss: 0.0295, best acc: 96.28%\n",
      "Epoch[16/25](200/414) || training loss 0.0134 || training accuracy 99.61% || lr 0.0001\n",
      "Epoch[16/25](400/414) || training loss 0.0142 || training accuracy 99.57% || lr 0.0001\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.9881! saving the best model..\n",
      "[Val] f1 : 0.9881, loss: 0.0344, acc: 96.23% || best f1 : 0.9881, best loss: 0.0295, best acc: 96.28%\n",
      "Epoch[17/25](200/414) || training loss 0.0120 || training accuracy 99.55% || lr 0.0001\n",
      "Epoch[17/25](400/414) || training loss 0.0124 || training accuracy 99.56% || lr 0.0001\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.9890! saving the best model..\n",
      "[Val] f1 : 0.9890, loss: 0.0304, acc: 96.35% || best f1 : 0.9890, best loss: 0.0295, best acc: 96.35%\n",
      "Epoch[18/25](200/414) || training loss 0.0128 || training accuracy 99.64% || lr 0.0001\n",
      "Epoch[18/25](400/414) || training loss 0.0129 || training accuracy 99.61% || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] f1 : 0.9863, loss: 0.0310, acc: 96.17% || best f1 : 0.9890, best loss: 0.0295, best acc: 96.35%\n",
      "Epoch[19/25](200/414) || training loss 0.0083 || training accuracy 99.78% || lr 0.0001\n",
      "Epoch[19/25](400/414) || training loss 0.0108 || training accuracy 99.69% || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] f1 : 0.9886, loss: 0.0299, acc: 96.31% || best f1 : 0.9890, best loss: 0.0295, best acc: 96.35%\n",
      "Epoch[20/25](200/414) || training loss 0.0080 || training accuracy 99.75% || lr 0.0001\n",
      "Epoch[20/25](400/414) || training loss 0.0094 || training accuracy 99.70% || lr 0.0001\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.9899! saving the best model..\n",
      "[Val] f1 : 0.9899, loss: 0.0327, acc: 96.37% || best f1 : 0.9899, best loss: 0.0295, best acc: 96.37%\n",
      "Epoch[21/25](200/414) || training loss 0.0056 || training accuracy 99.83% || lr 0.0001\n",
      "Epoch[21/25](400/414) || training loss 0.0063 || training accuracy 99.79% || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] f1 : 0.9878, loss: 0.0337, acc: 96.26% || best f1 : 0.9899, best loss: 0.0295, best acc: 96.37%\n",
      "Epoch[22/25](200/414) || training loss 0.0094 || training accuracy 99.70% || lr 0.0001\n",
      "Epoch[22/25](400/414) || training loss 0.0077 || training accuracy 99.77% || lr 0.0001\n",
      "Calculating validation results...\n",
      "New best model for val f1 : 0.9922! saving the best model..\n",
      "[Val] f1 : 0.9922, loss: 0.0267, acc: 96.54% || best f1 : 0.9922, best loss: 0.0267, best acc: 96.54%\n",
      "Epoch[23/25](200/414) || training loss 0.0067 || training accuracy 99.72% || lr 0.0001\n",
      "Epoch[23/25](400/414) || training loss 0.0095 || training accuracy 99.63% || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] f1 : 0.9877, loss: 0.0318, acc: 96.24% || best f1 : 0.9922, best loss: 0.0267, best acc: 96.54%\n",
      "Epoch[24/25](200/414) || training loss 0.0099 || training accuracy 99.70% || lr 0.0001\n",
      "Epoch[24/25](400/414) || training loss 0.0093 || training accuracy 99.70% || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] f1 : 0.9874, loss: 0.0261, acc: 96.33% || best f1 : 0.9922, best loss: 0.0261, best acc: 96.54%\n",
      "Epoch[25/25](200/414) || training loss 0.0075 || training accuracy 99.83% || lr 0.0001\n",
      "Epoch[25/25](400/414) || training loss 0.0061 || training accuracy 99.81% || lr 0.0001\n",
      "Calculating validation results...\n",
      "[Val] f1 : 0.9905, loss: 0.0290, acc: 96.49% || best f1 : 0.9922, best loss: 0.0261, best acc: 96.54%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_val_acc = 0\n",
    "best_val_f1 = 0\n",
    "best_val_loss = np.Inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_preds = []\n",
    "    epoch_labels = []\n",
    "\n",
    "    iter_preds = []\n",
    "    iter_labels = []\n",
    "\n",
    "    for idx, train_batch in enumerate(train_loader):\n",
    "        b_imgs, b_labels = train_batch # batch imgs and batch labels\n",
    "        b_imgs = b_imgs.to(device)\n",
    "        b_labels = b_labels.to(device)\n",
    "\n",
    "        b_logits = model(b_imgs)\n",
    "        b_loss = criterion(b_logits, b_labels)\n",
    "        b_preds = torch.argmax(b_logits, dim=-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        b_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += b_loss.item()\n",
    "        epoch_preds += b_preds.detach().cpu().numpy().tolist()\n",
    "        epoch_labels += b_labels.detach().cpu().numpy().tolist()\n",
    "\n",
    "        # print interval batch\n",
    "        if(idx+1) % print_interval == 0:\n",
    "            current_loss = epoch_loss / (idx+1) # /batch\n",
    "            correct_list = [i==j for i,j in zip(epoch_preds, epoch_labels)]\n",
    "            current_acc = sum(correct_list) / len(correct_list)\n",
    "            print(\n",
    "                    f\"Epoch[{epoch+1}/{epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                    f\"training loss {current_loss:2.4f} || training accuracy {current_acc:4.2%} || lr {lr}\"\n",
    "                )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"Calculating validation results...\")\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = []\n",
    "        val_acc = []\n",
    "\n",
    "        val_preds = [] # every data's preds\n",
    "        val_labels = [] # every data's label\n",
    "\n",
    "        for idx, val_batch in enumerate(val_loader):\n",
    "            imgs, labels = val_batch\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # print('labels shape:', labels.size())\n",
    "\n",
    "            logits = model(imgs)\n",
    "            b_loss = criterion(logits, labels).item()\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            # print('preds shape:', preds.size())\n",
    "\n",
    "            correct_num = (labels == preds).sum().item()\n",
    "\n",
    "            val_loss.append(b_loss)\n",
    "            val_acc.append(correct_num)\n",
    "\n",
    "            val_preds += preds.detach().cpu().numpy().tolist()\n",
    "            val_labels += labels.detach().cpu().numpy().tolist()\n",
    "\n",
    "        epoch_val_loss =  np.sum(val_loss)/len(val_loader)\n",
    "        epoch_val_acc = np.sum(val_acc)/len(val_dset)\n",
    "        epoch_val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "        \n",
    "        best_val_loss = min(best_val_loss, epoch_val_loss)\n",
    "\n",
    "        if epoch_val_f1 > best_val_f1:\n",
    "                print(f\"New best model for val f1 : {epoch_val_f1:2.4f}! saving the best model..\")\n",
    "                best_val_f1 = epoch_val_f1\n",
    "                torch.save(model.module.state_dict(), f\"{save_dir}/best.pth\")\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "                best_val_acc = epoch_val_acc\n",
    "        torch.save(model.module.state_dict(), f'{save_dir}/last.pth')\n",
    "        print(\n",
    "                f\"[Val] f1 : {epoch_val_f1:2.4f}, loss: {epoch_val_loss:2.4f}, acc: {epoch_val_acc:4.2%} || \"\n",
    "                f\"best f1 : {best_val_f1:2.4f}, best loss: {best_val_loss:2.4f}, best acc: {best_val_acc:4.2%}\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "{\n",
    "    \"seed\": 42,\n",
    "    \"train_b_size\": 32,\n",
    "    \"epochs\": 25,\n",
    "    \"lr\": 0.0001,\n",
    "    \"model_name\": \"efficientnet_b4\",\n",
    "    \"num_labels\": 6,\n",
    "    \"loss_function_name\": \"CrossEntropyLoss\",\n",
    "    \"optimizer_name\": \"AdamW\",\n",
    "    \"comment\": \"For classification Mask, Gender\"\n",
    "}\n",
    "[Val] f1 : 0.9905, loss: 0.0290, acc: 96.49% || best f1 : 0.9922, best loss: 0.0261, best acc: 96.54%\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet34'\n",
    "check_point_dir_name = 'resnet34'\n",
    "save_file_path = f'./checkpoints/{check_point_dir_name}/best.pth'\n",
    "test_dir = './dataset/eval/images/'\n",
    "test_csv_path = './dataset/eval/info.csv'\n",
    "\n",
    "test_b_size = 1000\n",
    "num_labels = 18\n",
    "sumbission_csv_name = 'result'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checkpoint model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(model_name=model_name, pretrained=False, num_classes=num_labels)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(save_file_path))\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, img_paths:list, transforms=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.transforms = transforms\n",
    "        assert self.transforms is not None, 'you must use transforms in Testset'\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_paths[index])\n",
    "        img = np.array(img)\n",
    "        img = self.transforms(image=img)[\"image\"]\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = A.Compose([A.Resize(height=224, width=224),\n",
    "                                 A.Normalize(mean=(0.56019358,0.52410121,0.501457),\n",
    "                                 std=(0.23318603,0.24300033,0.24567522)),\n",
    "                                 ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_csv(test_csv_path)\n",
    "test_imgs_path = [os.path.join(test_dir, img_id) for img_id in info.ImageID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dset = CustomTestDataset(test_imgs_path, test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "        test_dset,\n",
    "        batch_size=test_b_size,\n",
    "        num_workers=multiprocessing.cpu_count() // 2,\n",
    "        shuffle=False,\n",
    "        pin_memory=use_cuda,\n",
    "        drop_last=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "        for idx, images in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            pred = model(images)\n",
    "            pred = pred.argmax(dim=-1)\n",
    "            test_preds.extend(pred.cpu().numpy().tolist())\n",
    "\n",
    "info['ans'] = test_preds\n",
    "save_path = os.path.join(save_dir, f'{sumbission_csv_name}.csv')\n",
    "info.to_csv(save_path, index=False)\n",
    "print(f\"Inference Done! Inference result saved at {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
