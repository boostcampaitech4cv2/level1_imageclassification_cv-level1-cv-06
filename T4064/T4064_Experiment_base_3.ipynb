{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy Experiment .ipynb File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import multiprocessing\n",
    "import timm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cofiguration\n",
    "seed = 42\n",
    "check_point_dir_name = 'efficientnet_b4'\n",
    "\n",
    "data_dir = './dataset/train/images/'\n",
    "train_csv_path = './dataset/train/custom_train.csv'\n",
    "save_dir = f'./checkpoints/{check_point_dir_name}'\n",
    "\n",
    "train_b_size = 64\n",
    "valid_b_size = 1000\n",
    "epochs = 20\n",
    "print_interval = 100\n",
    "lr = 1e-4\n",
    "model_name = 'efficientnet_b4'\n",
    "num_labels = 18\n",
    "loss_function_name = 'CrossEntropyLoss' # ex....\n",
    "optimizer_name = 'AdamW'\n",
    "comment = 'For Error label amend'\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_csv_path)\n",
    "imgs_path = train_df['path'] \n",
    "labels = train_df['class'] # input your label feature\n",
    "stratify_col = train_df['class']\n",
    "\n",
    "train_paths, valid_paths, train_labels, valid_labels = train_test_split(imgs_path, labels,\n",
    "                                                                        train_size=0.7,\n",
    "                                                                        shuffle=True,\n",
    "                                                                        random_state=seed,\n",
    "                                                                        stratify=stratify_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(save_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dict_args = {\n",
    "'seed' : seed,\n",
    "'train_b_size': train_b_size,\n",
    "'epochs' : 1,\n",
    "'lr' : 1e-4,\n",
    "'model_name' : model_name,\n",
    "'num_labels' : num_labels,\n",
    "'loss_function_name' : loss_function_name,\n",
    "'optimizer_name' : optimizer_name,\n",
    "'comment' : comment\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_dir, 'config.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(dict_args, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## datasets class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainDataset(Dataset):\n",
    "    ## input pd.Series\n",
    "    ## output np.ndarray\n",
    "    ## change dummy, if label_col is 'gender' or 'mask_state'\n",
    "    def __init__(self, img_paths : pd.Series, labels : pd.Series, label_col='class', transforms=None):\n",
    "        self.img_paths = img_paths.to_numpy()\n",
    "        self.transforms = transforms\n",
    "        if label_col == 'gender':\n",
    "            self.labels = pd.get_dummies(labels).to_numpy()\n",
    "        elif label_col == 'mask_state':\n",
    "            self.labels = pd.get_dummies(labels).to_numpy()\n",
    "        else: # age, classes\n",
    "            self.labels = labels.to_numpy()\n",
    "        ## if (False), assert occur\n",
    "        assert self.transforms is not None, 'you must use transforms in Trainset'\n",
    "    \n",
    "    ## return numpy img, label\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        img = np.array(Image.open(img_path))\n",
    "\n",
    "        img = self.transforms(image=img)[\"image\"]\n",
    "        label = self.labels[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = A.Compose([A.Resize(height=224, width=224),\n",
    "                              A.HorizontalFlip(p=0.5),\n",
    "                              A.RandomBrightnessContrast(p=0.5),\n",
    "                              A.GaussianBlur(p=0.5),\n",
    "                              A.GridDistortion(p=0.5),\n",
    "                              A.Rotate(limit=30, p=0.5),\n",
    "                              A.Normalize(mean=(0.56019358,0.52410121,0.501457),\n",
    "                              std=(0.23318603,0.24300033,0.24567522)),\n",
    "                              ToTensorV2()])\n",
    "\n",
    "valid_transforms = A.Compose([A.Resize(height=224, width=224),\n",
    "                              A.Normalize(mean=(0.56019358,0.52410121,0.501457),\n",
    "                              std=(0.23318603,0.24300033,0.24567522)),\n",
    "                              ToTensorV2()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = CustomTrainDataset(train_paths, train_labels, 'class', train_transforms)\n",
    "val_dset = CustomTrainDataset(valid_paths, valid_labels, 'class', valid_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "        train_dset,\n",
    "        batch_size=train_b_size,\n",
    "        num_workers=multiprocessing.cpu_count() // 2,\n",
    "        shuffle=True,\n",
    "        pin_memory=use_cuda,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "        val_dset,\n",
    "        batch_size=valid_b_size,\n",
    "        num_workers=multiprocessing.cpu_count() // 2,\n",
    "        shuffle=False,\n",
    "        pin_memory=use_cuda,\n",
    "        drop_last=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for check transform\n",
    "imgs, labels = next(iter(train_loader))\n",
    "plt.imshow(make_grid(imgs, normalize=True).permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(model_name=model_name, pretrained=True, num_classes=num_labels)\n",
    "model.to(device)\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Loss(nn.Module):\n",
    "    def __init__(self, classes=3, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.classes = classes\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.ndim == 2\n",
    "        assert y_true.ndim == 1\n",
    "        y_true = F.one_hot(y_true, self.classes).to(torch.float32)\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "\n",
    "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
    "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
    "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1 - self.epsilon)\n",
    "        return 1 - f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loss_function_name == 'CrossEntropyLoss':\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "elif loss_function_name == 'F1':\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError(f'not implement Loss function : {loss_function_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "just input AdamW Optim",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [229], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     optimizer \u001b[39m=\u001b[39m AdamW(\u001b[39mfilter\u001b[39m(\u001b[39mlambda\u001b[39;00m p: p\u001b[39m.\u001b[39mrequires_grad, model\u001b[39m.\u001b[39mparameters()), lr\u001b[39m=\u001b[39mlr) \n\u001b[1;32m      6\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mjust input AdamW Optim\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: just input AdamW Optim"
     ]
    }
   ],
   "source": [
    "# if you param freeze, not update during training\n",
    "optimizer = None\n",
    "if optimizer_name == 'AdamW':\n",
    "    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr) \n",
    "else:\n",
    "    raise ValueError(f'not implement Optimizer : {optimizer_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_val_acc = 0\n",
    "best_val_f1 = 0\n",
    "best_val_loss = np.Inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_preds = []\n",
    "    epoch_labels = []\n",
    "\n",
    "    iter_preds = []\n",
    "    iter_labels = []\n",
    "\n",
    "    for idx, train_batch in enumerate(train_loader):\n",
    "        b_imgs, b_labels = train_batch # batch imgs and batch labels\n",
    "        b_imgs = b_imgs.to(device)\n",
    "        b_labels = b_labels.to(device)\n",
    "\n",
    "        b_logits = model(b_imgs)\n",
    "        b_loss = criterion(b_logits, b_labels)\n",
    "        b_preds = torch.argmax(b_logits, dim=-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        b_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += b_loss.item()\n",
    "        epoch_preds += b_preds.detach().cpu().numpy().tolist()\n",
    "        epoch_labels += b_labels.detach().cpu().numpy().tolist()\n",
    "\n",
    "        # print interval batch\n",
    "        if(idx+1) % print_interval == 0:\n",
    "            current_loss = epoch_loss / (idx+1) # /batch\n",
    "            correct_list = [i==j for i,j in zip(epoch_preds, epoch_labels)]\n",
    "            current_acc = sum(correct_list) / len(correct_list)\n",
    "            print(\n",
    "                    f\"Epoch[{epoch+1}/{epochs}]({idx + 1}/{len(train_loader)}) || \"\n",
    "                    f\"training loss {current_loss:2.4f} || training accuracy {current_acc:4.2%} || lr {lr}\"\n",
    "                )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"Calculating validation results...\")\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = []\n",
    "        val_acc = []\n",
    "\n",
    "        val_preds = [] # every data's preds\n",
    "        val_labels = [] # every data's label\n",
    "\n",
    "        for idx, val_batch in enumerate(val_loader):\n",
    "            imgs, labels = val_batch\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # print('labels shape:', labels.size())\n",
    "\n",
    "            logits = model(imgs)\n",
    "            b_loss = criterion(logits, labels).item()\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            # print('preds shape:', preds.size())\n",
    "\n",
    "            correct_num = (labels == preds).sum().item()\n",
    "\n",
    "            val_loss.append(b_loss)\n",
    "            val_acc.append(correct_num)\n",
    "\n",
    "            val_preds += preds.detach().cpu().numpy().tolist()\n",
    "            val_labels += labels.detach().cpu().numpy().tolist()\n",
    "\n",
    "        epoch_val_loss =  np.sum(val_loss)/len(val_loader)\n",
    "        epoch_val_acc = np.sum(val_acc)/len(val_dset)\n",
    "        epoch_val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "        \n",
    "        best_val_loss = min(best_val_loss, epoch_val_loss)\n",
    "\n",
    "        if epoch_val_f1 > best_val_f1:\n",
    "                print(f\"New best model for val f1 : {epoch_val_f1:2.4f}! saving the best model..\")\n",
    "                best_val_f1 = epoch_val_f1\n",
    "                torch.save(model.module.state_dict(), f\"{save_dir}/best.pth\")\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "                best_val_acc = epoch_val_acc\n",
    "        torch.save(model.module.state_dict(), f'{save_dir}/last.pth')\n",
    "        print(\n",
    "                f\"[Val] f1 : {epoch_val_f1:2.4f}, loss: {epoch_val_loss:2.4f}, acc: {epoch_val_acc:4.2%} || \"\n",
    "                f\"best f1 : {best_val_f1:2.4f}, best loss: {best_val_loss:2.4f}, best acc: {best_val_acc:4.2%}\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet34'\n",
    "check_point_dir_name = 'resnet34'\n",
    "save_file_path = f'./checkpoints/{check_point_dir_name}/best.pth'\n",
    "test_dir = './dataset/eval/images/'\n",
    "test_csv_path = './dataset/eval/info.csv'\n",
    "\n",
    "test_b_size = 1000\n",
    "num_labels = 18\n",
    "sumbission_csv_name = 'result'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checkpoint model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(model_name=model_name, pretrained=False, num_classes=num_labels)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(save_file_path))\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, img_paths:list, transforms=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.transforms = transforms\n",
    "        assert self.transforms is not None, 'you must use transforms in Testset'\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_paths[index])\n",
    "        img = np.array(img)\n",
    "        img = self.transforms(image=img)[\"image\"]\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = A.Compose([A.Resize(height=224, width=224),\n",
    "                                 A.Normalize(mean=(0.56019358,0.52410121,0.501457),\n",
    "                                 std=(0.23318603,0.24300033,0.24567522)),\n",
    "                                 ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.read_csv(test_csv_path)\n",
    "test_imgs_path = [os.path.join(test_dir, img_id) for img_id in info.ImageID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dset = CustomTestDataset(test_imgs_path, test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "        test_dset,\n",
    "        batch_size=test_b_size,\n",
    "        num_workers=multiprocessing.cpu_count() // 2,\n",
    "        shuffle=False,\n",
    "        pin_memory=use_cuda,\n",
    "        drop_last=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "        for idx, images in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            pred = model(images)\n",
    "            pred = pred.argmax(dim=-1)\n",
    "            test_preds.extend(pred.cpu().numpy().tolist())\n",
    "\n",
    "info['ans'] = test_preds\n",
    "save_path = os.path.join(save_dir, f'{sumbission_csv_name}.csv')\n",
    "info.to_csv(save_path, index=False)\n",
    "print(f\"Inference Done! Inference result saved at {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
