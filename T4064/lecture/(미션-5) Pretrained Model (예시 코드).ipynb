{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "-MS3bWUNUSgz",
   "metadata": {
    "id": "-MS3bWUNUSgz"
   },
   "source": [
    "## Lesson 6 - Pretrained Model\n",
    "**미션 개요**\n",
    "- 이번 실습 자료에서는 강의시간에 다루었던 torchvision 을 사용하여 pretrained 모델을 사용하는 방법에 대해 실습하겠습니다.\n",
    "\n",
    "**미션의 목적 및 배경**\n",
    "- 파이토치에는 유명하고 근본이 되는 많은 pretrained 모델들을 쉽게 사용하기 위한 기능들이 많이 있습니다.\n",
    "- 나만의 모델 아키텍쳐를 디자인하여 모델링을 시도하는 것도 좋은 방법이나, 이미 유명하고 많은 사람들이 사용하여 검증된 모델 아키텍쳐로 심지어 어느정도 학습도 된 pretrained 모델을 사용하여 모델링을 시작하는 것이 현명한 방법일 수 있습니다.\n",
    "\n",
    "\n",
    "**미션 수행으로 얻어갈 수 있는 역량**\n",
    "- 다양한 근본이 되는 pretrained 모델의 종류에 대해 배우고 이것들을 다운로드 받아서 load 하고 사용하는 방법들에 대해 배웁니다.\n",
    "- 다른 유명 모델들은 layer 를 어떤 방식으로 쌓아가는지 살펴보면서 어떤 테크닉들과 노하우들이 있는지 배울 수 있습니다.\n",
    "\n",
    "**미션 핵심 내용**\n",
    "- torchvision 을 통해 다양한 pretrained 모델을 load 해보고 그 내부 구현을 살펴본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c1a56",
   "metadata": {},
   "source": [
    "\n",
    "- torchvision 의 pretrained model 리스트는 다음과 같습니다\n",
    " \n",
    " [List of torchvision models](https://github.com/pytorch/vision/blob/main/torchvision/models/__init__.py#L1-L18)\n",
    "```\n",
    "from .alexnet import *\n",
    "from .convnext import *\n",
    "from .densenet import *\n",
    "from .efficientnet import *\n",
    "from .googlenet import *\n",
    "from .inception import *\n",
    "from .mnasnet import *\n",
    "from .mobilenet import *\n",
    "from .regnet import *\n",
    "from .resnet import *\n",
    "from .shufflenetv2 import *\n",
    "from .squeezenet import *\n",
    "from .vgg import *\n",
    "from .vision_transformer import *\n",
    "from .swin_transformer import *\n",
    "from .maxvit import *\n",
    "from . import detection, optical_flow, quantization, segmentation, video\n",
    "from ._api import get_model, get_model_builder, get_model_weights, get_weight, list_models\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QfXG-tzwUSgv",
   "metadata": {
    "id": "QfXG-tzwUSgv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "D2BlaYvVUSg0",
   "metadata": {
    "id": "D2BlaYvVUSg0"
   },
   "source": [
    "#### 가장 기본이라고 할 수 있는 Alextnet 모델 아키텍쳐를 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8PT7gW-wUSg0",
   "metadata": {
    "id": "8PT7gW-wUSg0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision.models import alexnet\n",
    "model = alexnet()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kzOWtmBxUSg2",
   "metadata": {
    "id": "kzOWtmBxUSg2"
   },
   "source": [
    "#### Alexnet 의 pretrained 버전 또한 쉽게 불러올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36Rqc5-OUSg2",
   "metadata": {
    "id": "36Rqc5-OUSg2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = alexnet(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3799RyCBUSg3",
   "metadata": {
    "id": "3799RyCBUSg3"
   },
   "source": [
    "#### torchvision 에서 해당 모델을 어떤 식으로 구현하였는지 직접 확인해보면 매우 도움이 많으 됩니다.\n",
    "Example:\n",
    "[source code](https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py#L15-L50)\n",
    "```\n",
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GCagXJS2USg4",
   "metadata": {
    "id": "GCagXJS2USg4"
   },
   "source": [
    "#### 다른 모델들( e.g. vgg19, resnet18) 도 같은 방법으로 손 쉽게 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tsZbkfObUSg5",
   "metadata": {
    "id": "tsZbkfObUSg5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision.models import vgg19_bn\n",
    "model = vgg19_bn(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foiF_enTUSg5",
   "metadata": {
    "id": "foiF_enTUSg5"
   },
   "source": [
    "#### Pretrained 모델을 내 태스크에 맞게 어떻게 사용할 수 있나요?\n",
    " - Trochvision 모델들은 보통 feature-extraction 파트, task-specific 파트로 크게 두 가지로 구성되어 있습니다.\n",
    " - Task specific 파트는 모델의 태스크(이미지 분류, 객체 인식 등) 에 따라 모두 다릅니다.\n",
    " - 심지어 같은 이미지 분류 안에서도, 어떤 데이터셋으로 pretrain 하였느냐에 따라 다를 수 있습니다.\n",
    " - 따라서, 우리도 우리 테스크에 맞게 task specific 파트는 새로 정의하여 사용하여야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nYv1DZ69USg6",
   "metadata": {
    "id": "nYv1DZ69USg6"
   },
   "source": [
    " - 주로 이미지넷 데이터셋을 사용하여 pretrain 을 하기에 output_dim=1000 인 경우가 많습니다.\n",
    " - 따라서 우리 태스크의 클래스 갯수(18)에 맞게 재정의하여 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xQIxW_QRUSg6",
   "metadata": {
    "id": "xQIxW_QRUSg6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes = 18\n",
    "model = vgg19_bn(pretrained=True)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(512 * 7 * 7, 4096),\n",
    "    nn.ReLU(True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(True),\n",
    "    nn.Dropout(),\n",
    "    nn.Linear(4096, num_classes),\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bkuxurF2USg7",
   "metadata": {
    "id": "bkuxurF2USg7"
   },
   "source": [
    "#### Weight Freeze\n",
    " - Weight freeze 란 해당 모듈의 graident 는 역전파 하지 않아 학습을 하지 않는다는 의미입니다.\n",
    " - 예를 들어, 우리가 하려는 태스크가 pretrain 한 태스크와 매우 유사하다면, feature 파트는 freeze 하여 학습하지 않고 새로 정의한 task specific 파트만 학습하는 것이 좋은 방법일 수 있습니다.\n",
    " - weight freeze 는 `requires_grad` 를 사용하여 쉽게 구현할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qr2vjssZUSg7",
   "metadata": {
    "id": "Qr2vjssZUSg7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature 파트만 freeze\n",
    "model.features.requires_grad_(False)\n",
    "for param, weight in model.named_parameters():\n",
    "    print(f\"파라미터 {param:20} 가 gradient 를 tracking 하나요? -> {weight.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LM4aPLqeUSg8",
   "metadata": {
    "id": "LM4aPLqeUSg8"
   },
   "source": [
    "#### Weight initialization \n",
    " - weight 초기화는 종종 모델의 성능에 critical 한 영향을 줍니다.\n",
    " - 하지만 만약 pretrained 모델을 사용한다면 pretrained 부분은 초기화를 하지 말고, 재정의한 task specific 파트만 초기화하여야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "I_5s0otKUSg8",
   "metadata": {
    "id": "I_5s0otKUSg8"
   },
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "def initialize_weights(model):\n",
    "    \"\"\"\n",
    "    Xavier uniform 분포로 모든 weight 를 초기화합니다.\n",
    "    더 많은 weight 초기화 방법은 다음 문서에서 참고해주세요. https://pytorch.org/docs/stable/nn.init.html\n",
    "    \"\"\"\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.01)\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mRDhT8vnUSg9",
   "metadata": {
    "id": "mRDhT8vnUSg9"
   },
   "source": [
    "#### pretrained 모델을 가져와 가장 앞단 layer 의 weight 분포를 봐봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GNghuOsYUSg9",
   "metadata": {
    "id": "GNghuOsYUSg9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = vgg19_bn(pretrained=True)\n",
    "\n",
    "# Weight Initialization 이전 모델 feature 파트의 첫번째 weight 분포\n",
    "plt.hist(model.features[0].weight.detach().numpy().reshape(-1))  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yeAhmcpbUSg-",
   "metadata": {
    "id": "yeAhmcpbUSg-"
   },
   "source": [
    "#### weight 초기화 후 분포를 봐 봅시다\n",
    " - `xavier_uniform` 으로 초기화하여 웨이트들이 uniform 한 분포를 가지게 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ISYQG_TDUSg-",
   "metadata": {
    "id": "ISYQG_TDUSg-"
   },
   "outputs": [],
   "source": [
    "model = vgg19_bn(pretrained=True)\n",
    "\n",
    "# 모든 weight 를 initialize\n",
    "initialize_weights(model.features)\n",
    "\n",
    "# Weight Initialization 이후 모델 feature 파트의 첫번째 weight 분포\n",
    "# (xavier) uniform 한 분포로 바뀐 것을 확인할 수 있습니다.\n",
    "plt.hist(model.features[0].weight.detach().numpy().reshape(-1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbqr7onnUSg_",
   "metadata": {
    "id": "fbqr7onnUSg_"
   },
   "source": [
    "#### task specific 한 부분만 초기화하엿습니다\n",
    " - feature extraction 파트는 초기화가 되지 않은 것은 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kvlDANr6USg_",
   "metadata": {
    "id": "kvlDANr6USg_"
   },
   "outputs": [],
   "source": [
    "model = vgg19_bn(pretrained=True)\n",
    "\n",
    "# Classifier 부분만 initialize\n",
    "initialize_weights(model.classifier)\n",
    "\n",
    "# Weight Initialization 이후 모델 feature 파트의 첫번째 weight 분포\n",
    "# classifier 부분만 xavier uniform 으로 초기화해서 feature 파트는 uniform 한 분포를 가지지 않는 것을 확인할 수 있습니다.\n",
    "plt.hist(model.features[0].weight.detach().numpy().reshape(-1)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o5rYLwDKUSg_",
   "metadata": {
    "id": "o5rYLwDKUSg_"
   },
   "source": [
    "## Appendix (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DYtGOREKUShA",
   "metadata": {
    "id": "DYtGOREKUShA"
   },
   "source": [
    "### SOTA (State Of The Art)  모델을 리서치 하는 방법\n",
    "- timm\n",
    "- paper with code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2IlmlHvDUShA",
   "metadata": {
    "id": "2IlmlHvDUShA"
   },
   "source": [
    "## timm (pyTorch IMage Models)\n",
    "\n",
    "PyTorch Image Models (timm) is a collection of image models, layers, utilities, optimizers, schedulers, data-loaders / augmentations, and reference training / validation scripts that aim to pull together a wide variety of SOTA models with ability to reproduce ImageNet training results.\n",
    "\n",
    "#### References\n",
    "https://github.com/rwightman/pytorch-image-models#introduction\n",
    "\n",
    "https://fastai.github.io/timmdocs/\n",
    "\n",
    "https://rwightman.github.io/pytorch-image-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qLTgGr7EUShA",
   "metadata": {
    "id": "qLTgGr7EUShA"
   },
   "outputs": [],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yF6B71PxUShA",
   "metadata": {
    "id": "yF6B71PxUShA"
   },
   "source": [
    "#### Timm 을 사용하여 pretrained 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R2dV1z-1UShB",
   "metadata": {
    "id": "R2dV1z-1UShB"
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "m = timm.create_model('mobilenetv3_large_100', pretrained=True)\n",
    "m.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NxpGBf1HUShB",
   "metadata": {
    "id": "NxpGBf1HUShB"
   },
   "source": [
    "#### Timm 에서 사용가능한 pretrained 모델 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MnZYn5SlUShB",
   "metadata": {
    "id": "MnZYn5SlUShB"
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models(pretrained=True)\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GuK012_QUShC",
   "metadata": {
    "id": "GuK012_QUShC"
   },
   "source": [
    "#### 다음과 같은 방법을 통해서 원하는 모델을 찾는 것도 가능합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8q11NdteUShC",
   "metadata": {
    "id": "8q11NdteUShC"
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "from pprint import pprint\n",
    "model_names = timm.list_models('*resne*t*')\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_3W3me_bUShC",
   "metadata": {
    "id": "_3W3me_bUShC"
   },
   "source": [
    "## Paper with code\n",
    " - https://paperswithcode.com/task/image-classification\n",
    " - 다양한 태스크와 데이터셋에 대한 다양한 모델들의 성능을 벤치마킹해주는 웹서비스입니다.\n",
    " - 해당 서비스를 통해 각 모델들의 성능 비교뿐 아니라 논문과 구현 코드로 forwarding 도 가능합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26c9788",
   "metadata": {
    "id": "f26c9788"
   },
   "source": [
    "## 레이어 직접 쌓아보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb19115f",
   "metadata": {
    "id": "bb19115f"
   },
   "source": [
    "![python image2](https://cphinf.pstatic.net/mooc/20210813_264/1628827925318KzHFu_JPEG/mceclip0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e7d899",
   "metadata": {
    "id": "52e7d899"
   },
   "source": [
    "해당 모델 아키텍쳐는 향후 배우시게 될 Object Detection 쪽에서 하나의 큰 계보라 할 수 있는 yolo 의 backbone 으로 많이 사용하는 Darknet53 입니다\n",
    "\n",
    "Darknet53 은 ResidualBlock 을 해상도를 줄여가며(receptive field 를 늘려가며) 쌓은 구조를 가지고 있습니다.\n",
    "\n",
    "마지막 FC 레이어를 제외하고는 Feature Extraction Layer 로도 다양하게 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d900a7",
   "metadata": {
    "id": "52d900a7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def conv_batch(in_num, out_num, kernel_size=3, padding=1, stride=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_num, out_num, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(out_num),\n",
    "        nn.LeakyReLU())\n",
    "\n",
    "\n",
    "# Residual block\n",
    "class DarkResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(DarkResidualBlock, self).__init__()\n",
    "\n",
    "        reduced_channels = int(in_channels/2)\n",
    "\n",
    "        self.layer1 = conv_batch(in_channels, reduced_channels, kernel_size=1, padding=0)\n",
    "        self.layer2 = conv_batch(reduced_channels, in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "\n",
    "class Darknet53(nn.Module):\n",
    "    def __init__(self, block, num_classes):\n",
    "        super(Darknet53, self).__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            conv_batch(3, 32),\n",
    "            conv_batch(32, 64, stride=2),\n",
    "            self.make_layer(block, in_channels=64, num_blocks=1),\n",
    "            conv_batch(64, 128, stride=2),\n",
    "            self.make_layer(block, in_channels=128, num_blocks=2),\n",
    "            conv_batch(128, 256, stride=2),\n",
    "            self.make_layer(block, in_channels=256, num_blocks=8),\n",
    "            conv_batch(256, 512, stride=2),\n",
    "            self.make_layer(block, in_channels=512, num_blocks=8),\n",
    "            conv_batch(512, 1024, stride=2),\n",
    "            self.make_layer(block, in_channels=1024, num_blocks=4),\n",
    "        )\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(1024, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = self.global_avg_pool(out)\n",
    "        out = out.view(-1, 1024)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def make_layer(self, block, in_channels, num_blocks):\n",
    "        layers = []\n",
    "        for i in range(0, num_blocks):\n",
    "            layers.append(block(in_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def darknet53(num_classes):\n",
    "    return Darknet53(DarkResidualBlock, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7881dc94",
   "metadata": {
    "id": "7881dc94",
    "outputId": "bba77f2d-74e6-425a-b94d-9bdf6b3499a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Darknet53(\n",
       "  (features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (1): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (1): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (2): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (3): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (4): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (5): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (6): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (7): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (8): Sequential(\n",
       "      (0): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (1): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (2): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (3): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (4): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (5): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (6): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (7): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (10): Sequential(\n",
       "      (0): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (1): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (2): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "      (3): DarkResidualBlock(\n",
       "        (layer1): Sequential(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): LeakyReLU(negative_slope=0.01)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (classifier): Linear(in_features=1024, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = darknet53(num_classes=18)\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FACYl6fScLxx",
   "metadata": {
    "id": "FACYl6fScLxx"
   },
   "source": [
    "###**콘텐츠 라이선스**\n",
    "\n",
    "<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
