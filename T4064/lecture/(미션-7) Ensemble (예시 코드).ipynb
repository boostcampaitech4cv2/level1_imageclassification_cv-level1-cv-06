{"cells":[{"cell_type":"markdown","metadata":{"id":"djto-8vwvZZ9"},"source":["## Lesson 9 - Ensemble\n","**미션 개요**\n","- 이번 실습 자료에서는 강의시간에 다루었던 Straified kFold Cross Validation(교차 검증)과 이를 활용한 Out-Of-Fold Ensemble 및 Test Time Augmentation에 대해 다뤄보겠습니다. \n","\n","**미션의 목적 및 배경**\n","- k개의 Fold로 나누어 교차 검증하는 kFold Cross Validation은 기존 train, valid 로 나누어 한번만 검증하던 프로세스에서 조금 더 엄격하게 모델을 검증하는 방법입니다. \n","- kFold Cross Validation에서 학습한 k개의 모델의 결과를 앙상블 하는 것이 Out-Of-Fold(OOF) Ensemble 입니다.\n","- Test Time Augmentation은 Test 데이터의 결과를 예측할 때 Augmentation 기법을 적용해 여러번 예측하고, 예측한 결과들의 평균으로 결과를 내는 것을 말합니다. \n","- Sklearn의 kFold는 데이터셋의 인덱스로 Fold를 정의하므로 기존에 사용하던 DataSet이 아닌 인덱스로 생성한 Subset을 사용합니다. 이번 실습 자료에서는 매 이터레이션마다 생성한 SubSet 객체를 활용해 DataLoader를 반환해 학습 및 검증에 사용하게 됩니다.\n","\n","\n","**미션 수행으로 얻어갈 수 있는 역량**\n","- kFold Cross Validation, Ensemble, Test Time Augmentation 의 개념에 대해 학습합니다.\n","- Sklearn 을 이용하여 Stratified K Fold 를 사용하는 방법에 대해 실습합니다.\n","\n","**미션 핵심 내용**\n","- 교차 검증의 개념과 필요성에 대해 학습하고 이를 실제로 적용하는 방법을 배워봅니다.\n","\n","**데이터셋 개요 및 저작권 정보**\n","- Face with Masks\n","- 캠프 교육용 라이선스 : 교육 내에서만 활용해 주시고, 일부 이미지라도 외부에 노출되는 일은 없도록 부탁드립니다. (데이터셋에 대한 설명글이나, 데이터셋을 활용하여 학습한 weight 정도가 공개 가능합니다)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WgMumhVNvZZ5"},"outputs":[],"source":["import random\n","import os, sys\n","\n","import numpy as np\n","import torch\n","from torch.utils.data import Subset\n","from torch.optim import Adam\n","from torch.optim.lr_scheduler import StepLR\n","from torch.utils.tensorboard import SummaryWriter\n","from torch.utils.data import DataLoader\n","\n","from sklearn.model_selection import StratifiedKFold\n","\n","sys.path.append(os.path.abspath('..'))\n","\n","# BaseLine 코드로 주어진 dataset.py model.py, loss.py를 Import 합니다.\n","from dataset import MaskBaseDataset, BaseAugmentation\n","from model import *\n","from loss import create_criterion\n","\n","sys.path.append('../')\n","\n","def seed_everything(seed):\n","    \"\"\"\n","    동일한 조건으로 학습을 할 때, 동일한 결과를 얻기 위해 seed를 고정시킵니다.\n","    \n","    Args:\n","        seed: seed 정수값\n","    \"\"\"\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  # if use multi-GPU\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","seed_everything(42)"]},{"cell_type":"markdown","metadata":{"id":"tabskC3avZZ-"},"source":["### Model Parameter Setting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XduaWwdlvZZ-"},"outputs":[],"source":["# -- parameters\n","# img_root = '학습 이미지 폴더의 경로를 입력해주세요.'\n","\n","batch_size = 64\n","num_workers = 4\n","num_classes = 18\n","\n","num_epochs = 100  # 학습할 epoch의 수\n","lr = 1e-4\n","lr_decay_step = 10\n","criterion_name = 'cross_entropy' # loss의 이름\n","\n","train_log_interval = 20  # logging할 iteration의 주기\n","name = \"02_model_results\"  # 결과를 저장하는 폴더의 이름\n","\n","# -- settings\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"jONusDlUvZZ-"},"source":["### DataLoader\n","- index를 사용한 Dataloader 정의\n","- getDataloader 함수 설명\n","    1. Pytorch Dataset, train 인덱스, valid 인덱스, batch size를 전달받아 Train, Valid DataLoader 객체를 반환합니다.\n","    2. torch.utils.data.Subset 객체는 데이터셋과 해당 데이터셋의 인덱스를 전달받아 Subset 객체를 생성합니다. 생성한 Subset 객체를 사용해 DataLoader 객체를 반환합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oaHofXguvZZ_"},"outputs":[],"source":["def getDataloader(dataset, train_idx, valid_idx, batch_size, num_workers):\n","    # 인자로 전달받은 dataset에서 train_idx에 해당하는 Subset 추출\n","    train_set = torch.utils.data.Subset(dataset,\n","                                        indices=train_idx)\n","    # 인자로 전달받은 dataset에서 valid_idx에 해당하는 Subset 추출\n","    val_set   = torch.utils.data.Subset(dataset,\n","                                        indices=valid_idx)\n","    \n","    # 추출된 Train Subset으로 DataLoader 생성\n","    train_loader = torch.utils.data.DataLoader(\n","        train_set,\n","        batch_size=batch_size,\n","        num_workers=num_workers,\n","        drop_last=True,\n","        shuffle=True\n","    )\n","    # 추출된 Valid Subset으로 DataLoader 생성\n","    val_loader = torch.utils.data.DataLoader(\n","        val_set,\n","        batch_size=batch_size,\n","        num_workers=num_workers,\n","        drop_last=True,\n","        shuffle=False\n","    )\n","    \n","    # 생성한 DataLoader 반환\n","    return train_loader, val_loader"]},{"cell_type":"markdown","metadata":{"id":"lkUoWwJnvZZ_"},"source":["### Stratified k-Fold\n","1. k를 나타내는 n_splits 값을 설정해 StratifiedKFold 객체를 준비합니다. \n","2. skf.split(x, y) 메소드를 사용해 데이터셋의 인덱스를 얻어내고, 라벨(y)을 기준으로 Stratified를 진행합니다. \n","3. 매 이터레이션마다 반환받은 인덱스를 사용해 getDataloader 함수에 전달하여 DataLoader를 생성합니다.\n","4. 나머지 학습 프로세스는 이전 강의에서 사용한 프로세스와 동일하게 진행합니다.\n","- Stratify는 데이터셋을 분리하기 이전에 ```클래스 비율```을 분리한 이후에도 유지해주는 기능을 말합니다. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ExHJ2_qvvZZ_"},"outputs":[],"source":["img_root = '학습 이미지 폴더의 경로를 입력해주세요.'\n","\n","dataset = MaskBaseDataset(img_root)\n","\n","transform = BaseAugmentation(\n","    resize=[128, 96],\n","    mean=dataset.mean,\n","    std=dataset.std,\n",")\n","\n","dataset.set_transform(transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JiKcfgn_WUvl"},"outputs":[],"source":["def build_model():\n","    model = vgg19_bn(pretrained=True)\n","    model.classifier = nn.Sequential(\n","        nn.Linear(512 * 7 * 7, 4096),\n","        nn.ReLU(True),\n","        nn.Dropout(),\n","        nn.Linear(4096, 4096),\n","        nn.ReLU(True),\n","        nn.Dropout(),\n","        nn.Linear(4096, num_classes),\n","    )\n","    model.to(device)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FpsrKzcuvZZ_"},"outputs":[],"source":["from torchvision.models import vgg19_bn\n","\n","os.makedirs(os.path.join(os.getcwd(), 'results', name), exist_ok=True)\n","\n","# 5-fold Stratified KFold 5개의 fold를 형성하고 5번 Cross Validation을 진행합니다.\n","n_splits = 5\n","skf = StratifiedKFold(n_splits=n_splits)\n","\n","counter = 0\n","patience = 10\n","accumulation_steps = 2\n","best_val_acc = 0\n","best_val_loss = np.inf\n","\n","labels = [dataset.encode_multi_class(mask, gender, age) for mask, gender, age in zip(dataset.mask_labels, dataset.gender_labels, dataset.age_labels)]\n","\n","# Stratified KFold를 사용해 Train, Valid fold의 Index를 생성합니다.\n","# labels 변수에 담긴 클래스를 기준으로 Stratify를 진행합니다. \n","for i, (train_idx, valid_idx) in enumerate(skf.split(dataset.image_paths, labels)):\n","    \n","    # 생성한 Train, Valid Index를 getDataloader 함수에 전달해 train/valid DataLoader를 생성합니다.\n","    # 생성한 train, valid DataLoader로 이전과 같이 모델 학습을 진행합니다. \n","    train_loader, val_loader = getDataloader(dataset, train_idx, valid_idx, batch_size, num_workers)\n","\n","    # -- model\n","    model = build_model()\n","\n","    # -- loss & metric\n","    criterion = create_criterion(criterion_name)\n","    train_params = [{'params': getattr(model, 'features').parameters(), 'lr': lr / 10, 'weight_decay':5e-4},\n","                    {'params': getattr(model, 'classifier').parameters(), 'lr': lr, 'weight_decay':5e-4}]\n","    optimizer = Adam(train_params)\n","    scheduler = StepLR(optimizer, lr_decay_step, gamma=0.5)\n","\n","    # -- logging\n","    logger = SummaryWriter(log_dir=f\"results/cv{i}_{name}\")\n","    for epoch in range(num_epochs):\n","        # train loop\n","        model.train()\n","        loss_value = 0\n","        matches = 0\n","        for idx, train_batch in enumerate(train_loader):\n","            inputs, labels = train_batch\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outs = model(inputs)\n","            preds = torch.argmax(outs, dim=-1)\n","            loss = criterion(outs, labels)\n","\n","            loss.backward()\n","            \n","             # -- Gradient Accumulation\n","            if (idx+1) % accumulation_steps == 0:\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","            loss_value += loss.item()\n","            matches += (preds == labels).sum().item()\n","            if (idx + 1) % train_log_interval == 0:\n","                train_loss = loss_value / train_log_interval\n","                train_acc = matches / batch_size / train_log_interval\n","                current_lr = scheduler.get_last_lr()\n","                print(\n","                    f\"Epoch[{epoch}/{num_epochs}]({idx + 1}/{len(train_loader)}) || \"\n","                    f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}\"\n","                )\n","\n","                loss_value = 0\n","                matches = 0\n","\n","        scheduler.step()\n","\n","        # val loop\n","        with torch.no_grad():\n","            print(\"Calculating validation results...\")\n","            model.eval()\n","            val_loss_items = []\n","            val_acc_items = []\n","            for val_batch in val_loader:\n","                inputs, labels = val_batch\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                outs = model(inputs)\n","                preds = torch.argmax(outs, dim=-1)\n","\n","                loss_item = criterion(outs, labels).item()\n","                acc_item = (labels == preds).sum().item()\n","                val_loss_items.append(loss_item)\n","                val_acc_items.append(acc_item)\n","\n","            val_loss = np.sum(val_loss_items) / len(val_loader)\n","            val_acc = np.sum(val_acc_items) / len(valid_idx)\n","\n","            # Callback1: validation accuracy가 향상될수록 모델을 저장합니다.\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","            if val_acc > best_val_acc:\n","                print(\"New best model for val accuracy! saving the model..\")\n","                torch.save(model.state_dict(), f\"results/{name}/{epoch:03}_accuracy_{val_acc:4.2%}.ckpt\")\n","                best_val_acc = val_acc\n","                counter = 0\n","            else:\n","                counter += 1\n","            # Callback2: patience 횟수 동안 성능 향상이 없을 경우 학습을 종료시킵니다.\n","            if counter > patience:\n","                print(\"Early Stopping...\")\n","                break\n","\n","\n","            print(\n","                f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.2} || \"\n","                f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}\"\n","            )"]},{"cell_type":"markdown","metadata":{"id":"ee1GXk-qvZaA"},"source":["### Out-Of-Fold Ensemble with TTA\n","1. 이전 단계에서 작성한 k-Fold Cross Validation 코드에 각 폴드들의 예측 결과를 담을 oof_pred 변수를 준비합니다.\n","    - 생성한 행렬의 차원은 (Test set의 샘플 수, 예측할 클래스의 개수)로 정의됩니다. \n","    - 각 열에는 주어진 이미지가 해당 클래스일 확률을 담습니다. (Soft Voting), 여기에서 확률이 아닌 라벨로 앙상블을 진행하는 경우를 Hard Voting이라 합니다.\n","    - 확률을 저장할 때는 모든 확률의 합은 1이라는 확률의 정의를 유지하기 위해 확률을 k로 나누어 평균을 취해줍니다.\n","2. 각 행에 대해 가장 높은 확률을 갖는 클래스를 선택해 결과를 도출합니다.\n","3. 테스트 셋을 예측할 때 Augmentation 기법을 적용하여 Test Time Augmentation을 진행합니다. \n","    - 해당 실습 코드에서는 flip을 적용하여 2번 TTA를 진행합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zpv0075KvZaB"},"outputs":[],"source":["import pandas as pd\n","from torchvision.transforms import Resize, ToTensor, Normalize\n","\n","from dataset import TestDataset\n","\n","test_img_root = '학습 이미지 폴더의 경로'   \n","# public, private 테스트셋이 존재하니 각각의 예측결과를 저장합니다.\n","\n","# meta 데이터와 이미지 경로를 불러옵니다.\n","submission = pd.read_csv(os.path.join(test_img_root, 'info.csv'))\n","image_dir = os.path.join(test_img_root, 'images')\n","\n","# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n","image_paths = [os.path.join(image_dir, img_id) for img_id in submission.ImageID]\n","test_dataset = TestDataset(image_paths, resize=(128, 96))\n","\n","test_loader = DataLoader(\n","    test_dataset,\n","    shuffle=False\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eTKpGyHovZaB"},"outputs":[],"source":["os.makedirs(os.path.join(os.getcwd(), 'results', name), exist_ok=True)\n","\n","n_splits = 5\n","skf = StratifiedKFold(n_splits=n_splits)\n","\n","counter = 0\n","patience = 10\n","accumulation_steps = 2\n","best_val_acc = 0\n","best_val_loss = np.inf\n","oof_pred = None\n","\n","labels = [dataset.encode_multi_class(mask, gender, age) for mask, gender, age in zip(dataset.mask_labels, dataset.gender_labels, dataset.age_labels)]\n","\n","# K-Fold Cross Validation과 동일하게 Train, Valid Index를 생성합니다. \n","for i, (train_idx, valid_idx) in enumerate(skf.split(dataset.image_paths, labels)):\n","    train_loader, val_loader = getDataloader(dataset, train_idx, valid_idx, batch_size, num_workers)\n","\n","    # -- model\n","    model = build_model()\n","\n","    # -- loss & metric\n","    criterion = create_criterion(criterion_name)\n","    train_params = [{'params': getattr(model, 'features').parameters(), 'lr': lr / 10, 'weight_decay':5e-4},\n","                    {'params': getattr(model, 'classifier').parameters(), 'lr': lr, 'weight_decay':5e-4}]\n","    optimizer = Adam(train_params)\n","    scheduler = StepLR(optimizer, lr_decay_step, gamma=0.5)\n","\n","    # -- logging\n","    logger = SummaryWriter(log_dir=f\"results/cv{i}_{name}\")\n","    for epoch in range(num_epochs):\n","        # train loop\n","        model.train()\n","        loss_value = 0\n","        matches = 0\n","        for idx, train_batch in enumerate(train_loader):\n","            inputs, labels = train_batch\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","\n","            outs = model(inputs)\n","            preds = torch.argmax(outs, dim=-1)\n","            loss = criterion(outs, labels)\n","\n","            loss.backward()\n","            \n","             # -- Gradient Accumulation\n","            if (idx+1) % accumulation_steps == 0:\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","            loss_value += loss.item()\n","            matches += (preds == labels).sum().item()\n","            if (idx + 1) % train_log_interval == 0:\n","                train_loss = loss_value / train_log_interval\n","                train_acc = matches / batch_size / train_log_interval\n","                current_lr = scheduler.get_last_lr()\n","                print(\n","                    f\"Epoch[{epoch}/{num_epochs}]({idx + 1}/{len(train_loader)}) || \"\n","                    f\"training loss {train_loss:4.4} || training accuracy {train_acc:4.2%} || lr {current_lr}\"\n","                )\n","\n","                loss_value = 0\n","                matches = 0\n","\n","        scheduler.step()\n","\n","        # val loop\n","        with torch.no_grad():\n","            print(\"Calculating validation results...\")\n","            model.eval()\n","            val_loss_items = []\n","            val_acc_items = []\n","            for val_batch in val_loader:\n","                inputs, labels = val_batch\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                outs = model(inputs)\n","                preds = torch.argmax(outs, dim=-1)\n","\n","                loss_item = criterion(outs, labels).item()\n","                acc_item = (labels == preds).sum().item()\n","                val_loss_items.append(loss_item)\n","                val_acc_items.append(acc_item)\n","\n","            val_loss = np.sum(val_loss_items) / len(val_loader)\n","            val_acc = np.sum(val_acc_items) / len(valid_idx)\n","\n","            # Callback1: validation accuracy가 향상될수록 모델을 저장합니다.\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","            if val_acc > best_val_acc:\n","                print(\"New best model for val accuracy! saving the model..\")\n","                torch.save(model.state_dict(), f\"results/{name}/{epoch:03}_accuracy_{val_acc:4.2%}.ckpt\")\n","                best_val_acc = val_acc\n","                counter = 0\n","            else:\n","                counter += 1\n","            # Callback2: patience 횟수 동안 성능 향상이 없을 경우 학습을 종료시킵니다.\n","            if counter > patience:\n","                print(\"Early Stopping...\")\n","                break\n","\n","            print(\n","                f\"[Val] acc : {val_acc:4.2%}, loss: {val_loss:4.2} || \"\n","                f\"best acc : {best_val_acc:4.2%}, best loss: {best_val_loss:4.2}\"\n","            )\n","            \n","    # 각 fold에서 생성된 모델을 사용해 Test 데이터를 예측합니다. \n","    all_predictions = []\n","    with torch.no_grad():\n","        for images in test_loader:\n","            images = images.to(device)\n","\n","            # Test Time Augmentation\n","            pred = model(images) / 2 # 원본 이미지를 예측하고\n","            pred += model(torch.flip(images, dims=(-1,))) / 2 # horizontal_flip으로 뒤집어 예측합니다. \n","            all_predictions.extend(pred.cpu().numpy())\n","\n","        fold_pred = np.array(all_predictions)\n","\n","    # 확률 값으로 앙상블을 진행하기 때문에 'k'개로 나누어줍니다.\n","    if oof_pred is None:\n","        oof_pred = fold_pred / n_splits\n","    else:\n","        oof_pred += fold_pred / n_splits"]},{"cell_type":"markdown","metadata":{"id":"z_wCWSL-vZaC"},"source":["### Submission 파일 만들기\n","- 각 fold에서 예측한 결과의 확률을 평균낸 oof_pred에서 가장 높은 확률을 갖는 클래스를 추출하고 csv 파일을 생성합니다. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2lGYbEwAvZaC"},"outputs":[],"source":["submission['ans'] = np.argmax(oof_pred, axis=1)\n","submission.to_csv(os.path.join(test_img_root, 'submission.csv'), index=False)\n","\n","print('test inference is done!')"]},{"cell_type":"markdown","metadata":{"id":"6UPTR5zWcYcS"},"source":["###**콘텐츠 라이선스**\n","\n","<font color='red'><b>**WARNING**</b></font> : **본 교육 콘텐츠의 지식재산권은 재단법인 네이버커넥트에 귀속됩니다. 본 콘텐츠를 어떠한 경로로든 외부로 유출 및 수정하는 행위를 엄격히 금합니다.** 다만, 비영리적 교육 및 연구활동에 한정되어 사용할 수 있으나 재단의 허락을 받아야 합니다. 이를 위반하는 경우, 관련 법률에 따라 책임을 질 수 있습니다."]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":0}