{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import & config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "import requests\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "from torch.optim import *\n",
    "import timm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timm.list_models(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configurations\n",
    "train_folder_dir = 'G:/내 드라이브/Colab Notebooks/boost_camp_mask/level1_imageclassification_cv-level1-cv-06/T4064/dataset/train'\n",
    "eval_folder_dir = 'G:/내 드라이브/Colab Notebooks/boost_camp_mask/level1_imageclassification_cv-level1-cv-06/T4064/dataset/eval'\n",
    "\n",
    "train_imgs_dir = f'{train_folder_dir}/images'\n",
    "train_labels_path = f'{train_folder_dir}/train.csv'\n",
    "eval_imgs_dir = f'{eval_folder_dir}/images'\n",
    "eval_labels_path = f'{eval_folder_dir}/info.csv'\n",
    "\n",
    "cfg = {\n",
    "    'model_name' : 'resnet34',\n",
    "    'epochs' : 25,\n",
    "    'lr' : 1e-4,\n",
    "    'seed':42,\n",
    "    'num_classes':18\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000004</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000005</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000006</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>006954</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006954_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>006955</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006955_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>006956</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006956_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>006957</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>20</td>\n",
       "      <td>006957_male_Asian_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>006959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2700 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  gender   race  age                    path\n",
       "0     000001  female  Asian   45  000001_female_Asian_45\n",
       "1     000002  female  Asian   52  000002_female_Asian_52\n",
       "2     000004    male  Asian   54    000004_male_Asian_54\n",
       "3     000005  female  Asian   58  000005_female_Asian_58\n",
       "4     000006  female  Asian   59  000006_female_Asian_59\n",
       "...      ...     ...    ...  ...                     ...\n",
       "2695  006954    male  Asian   19    006954_male_Asian_19\n",
       "2696  006955    male  Asian   19    006955_male_Asian_19\n",
       "2697  006956    male  Asian   19    006956_male_Asian_19\n",
       "2698  006957    male  Asian   20    006957_male_Asian_20\n",
       "2699  006959    male  Asian   19    006959_male_Asian_19\n",
       "\n",
       "[2700 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(train_labels_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## csv 파일을 기반으로 img_path에 해당하는 class를 label_codes, img_paths 리스트에 저장하는 코드블럭\n",
    "\n",
    "df = pd.read_csv(train_labels_path)\n",
    "\n",
    "def get_label(mask_tag, gender, age):\n",
    "    gender = gender.lower()\n",
    "    label = 0\n",
    "    if mask_tag == 'Wear' and gender == 'male' and age<30: # 0:\n",
    "        label = 0\n",
    "    elif mask_tag == 'Wear' and gender == 'male' and 30<=age<60: # 1\n",
    "        label = 1\n",
    "    elif mask_tag == 'Wear' and gender == 'male' and age>=60: # 2\n",
    "        label = 2\n",
    "    elif mask_tag == 'Wear' and gender == 'female' and age<30: # 3\n",
    "        label = 3\n",
    "    elif mask_tag == 'Wear' and gender == 'female' and 30<=age<60: # 4\n",
    "        label = 4\n",
    "    elif mask_tag == 'Wear' and gender == 'female' and age>=60: # 5\n",
    "        label = 5\n",
    "    elif mask_tag == 'Incorrect' and gender == 'male' and age<30: # 6\n",
    "        label = 6\n",
    "    elif mask_tag == 'Incorrect' and gender == 'male' and 30<=age<60: # 7\n",
    "        label = 7\n",
    "    elif mask_tag == 'Incorrect' and gender == 'male' and age>=60: # 8\n",
    "        label = 8\n",
    "    elif mask_tag == 'Incorrect' and gender == 'female' and age<30: # 9\n",
    "        label = 9\n",
    "    elif mask_tag == 'Incorrect' and gender == 'female' and 30<=age<60: # 10\n",
    "        label = 10\n",
    "    elif mask_tag == 'Incorrect' and gender == 'female' and age>=60: # 11\n",
    "        label = 11\n",
    "    elif mask_tag == 'Not Wear' and gender == 'male' and age<30: # 12\n",
    "        label = 12\n",
    "    elif mask_tag == 'Not Wear' and gender == 'male' and 30<=age<60: # 13\n",
    "        label = 13\n",
    "    elif mask_tag == 'Not Wear' and gender == 'male' and age>=60: # 14\n",
    "        label = 14\n",
    "    elif mask_tag == 'Not Wear' and gender == 'female' and age<30: # 15\n",
    "        label = 15\n",
    "    elif mask_tag == 'Not Wear' and gender == 'female' and 30<=age<60: # 16\n",
    "        label = 16\n",
    "    elif mask_tag == 'Not Wear' and gender == 'female' and age>=60: # 17\n",
    "        label = 17\n",
    "    else:\n",
    "        raise ValueError\n",
    "    return label\n",
    "\n",
    "label_codes = []\n",
    "img_paths = []\n",
    "\n",
    "for gender, age, folder_name in zip(df['gender'], df['age'], df['path']):\n",
    "    folder_path = os.path.join(train_imgs_dir, folder_name)\n",
    "    files = os.listdir(folder_path)\n",
    "    for file_name in files:\n",
    "        img_path = os.path.join(folder_path,file_name)\n",
    "        if 'incorrect' in file_name:\n",
    "            label = get_label('Incorrect', gender, age)\n",
    "        elif 'mask' in file_name:\n",
    "            label = get_label('Wear', gender, age)\n",
    "        elif 'normal' in file_name:\n",
    "            label = get_label('Not Wear', gender, age)\n",
    "        else:\n",
    "            raise ValueError\n",
    "        img_paths.append(img_path)\n",
    "        label_codes.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/내 드라이브/Colab Notebooks/boost_camp_mask/level1_imageclassification_cv-level1-cv-06/T4064/dataset/train/images\\000001_female_Asian_45\\incorrect_mask.jpg 10\n"
     ]
    }
   ],
   "source": [
    "for path, code in zip(img_paths, label_codes):\n",
    "    print(path, code)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8967 8589 1344\n"
     ]
    }
   ],
   "source": [
    "## 나이 클래스별 분포를 확인\n",
    "counts = pd.DataFrame(label_codes).value_counts().sort_index()\n",
    "young = counts[0]+counts[3]+counts[6]+counts[9]+counts[12]+counts[15]\n",
    "middle = counts[1]+counts[4]+counts[7]+counts[10]+counts[13]+counts[16]\n",
    "old = counts[2]+counts[5]+counts[8]+counts[11]+counts[14]+counts[17]\n",
    "print(young, middle, old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 스플릿\n",
    "train_paths, valid_paths, train_labels, valid_labels = train_test_split(img_paths, label_codes,\n",
    "                                                                        train_size = 0.7,\n",
    "                                                                        shuffle = True,\n",
    "                                                                        random_state = hyper_params['seed'],\n",
    "                                                                        stratify=label_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.DataFrame(list(zip(train_paths, train_labels)), columns=['img_path', 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_csv = pd.DataFrame(list(zip(valid_paths, valid_labels)), columns=['img_path', 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13230 5670\n"
     ]
    }
   ],
   "source": [
    "print(len(train_csv), len(valid_csv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13225</th>\n",
       "      <td>G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13226</th>\n",
       "      <td>G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13227</th>\n",
       "      <td>G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13228</th>\n",
       "      <td>G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13229</th>\n",
       "      <td>G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13230 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                img_path  class\n",
       "0      G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...      0\n",
       "1      G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...     16\n",
       "2      G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...      4\n",
       "3      G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...      4\n",
       "4      G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...      4\n",
       "...                                                  ...    ...\n",
       "13225  G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...      4\n",
       "13226  G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...      4\n",
       "13227  G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...      7\n",
       "13228  G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...      3\n",
       "13229  G:/내 드라이브/Colab Notebooks/boost_camp_mask/leve...      0\n",
       "\n",
       "[13230 rows x 2 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "## csv파일을 받아서 리턴하는 Custom Dataset Class\n",
    "\n",
    "class MaskDataSet(Dataset):#train_labels_path\n",
    "    def __init__(self, path_df, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.path_df = path_df\n",
    "        if transforms is None: # transform이 없으면 자동으로 3개의 transform이 적용됨.\n",
    "            print('If transforms param is None automatically Resize(224), Normalize, ToTensorV2 Apply')\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.path_df['img_path'][index]\n",
    "        img = np.array(Image.open(img_path))\n",
    "        img_class = self.path_df['class'][index]\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "        else:\n",
    "            temp_transforms = A.Compose([A.Resize(height=224, width=224), A.Normalize(), ToTensorV2()])\n",
    "            img = temp_transforms(image=img)[\"image\"]\n",
    "        return img, img_class\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If transforms param is None automatically Resize(224), Normalize, ToTensorV2 Apply\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 16)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dset = MaskDataSet(train_csv)\n",
    "img, label = train_dset[1]\n",
    "img.size(), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If transforms param is None automatically Resize(224), Normalize, ToTensorV2 Apply\n"
     ]
    }
   ],
   "source": [
    "train_transforms = A.Compose([A.Resize(height=224, width=224),\n",
    "                              A.HorizontalFlip(p=0.5),\n",
    "                              A.RandomBrightnessContrast(p=0.5),\n",
    "                              A.GaussianBlur(p=0.5),\n",
    "                              A.GridDistortion(p=0.5),\n",
    "                              A.Rotate(limit=30, p=0.5),\n",
    "                              A.Normalize(mean=(0.56019358,0.52410121,0.501457),\n",
    "                                          std=(0.23318603,0.24300033,0.24567522)),\n",
    "                              ToTensorV2()])\n",
    "\n",
    "train_dataset = MaskDataSet(train_csv, train_transforms)\n",
    "valid_dataset = MaskDataSet(valid_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, l = train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (fc): Linear(in_features=512, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pretrain_model(config):\n",
    "    model_name = config['model_name']\n",
    "    model = timm.create_model(model_name=config['model_name'], pretrained=True, num_classes=config['num_classes'])\n",
    "    return model\n",
    "pretrained_model = get_pretrain_model(cfg)\n",
    "pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 10, 15, 10, 12,  0, 13,  7,  8, 13,  0,  5, 10, 15,  8,  8,  0, 12,\n",
       "        12,  9, 15, 11, 13,  0,  8,  0,  8,  5, 16,  3,  7, 14,  3,  9,  3,  2,\n",
       "        10, 13,  7, 10, 15,  7,  3,  8,  8, 12, 10,  8,  9,  3, 16,  8,  6,  8,\n",
       "         5,  8, 10,  3,  0, 10, 10,  3,  8,  7])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 테스트\n",
    "batch_images, batch_labels = next(iter(train_loader))\n",
    "torch.argmax(pretrained_model(batch_images), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## metric code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_valid(config, model, train_loader, valid_loader):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot result code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "631926b96873d2007fbe5ba14401cac9ce99e5e76ded0bffc18be58f3fefa61b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
