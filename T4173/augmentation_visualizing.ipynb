{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "049d90f6-8508-4a73-aba3-03bdf66bec55",
   "metadata": {},
   "source": [
    "# Libraries & Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf242f68-baed-4530-8d83-a71fcf34b25c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Tuple, List\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import multiprocessing as mp\n",
    "import cv2\n",
    "#from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "import random\n",
    "from enum import Enum\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import *\n",
    "\n",
    "import timm\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import Dataset, Subset, WeightedRandomSampler\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2a43f67-963f-42ab-8648-edcec1162c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5637c8a-501b-4709-8cff-242970376df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>45</td>\n",
       "      <td>000001_female_Asian_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>52</td>\n",
       "      <td>000002_female_Asian_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>54</td>\n",
       "      <td>000004_male_Asian_54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>58</td>\n",
       "      <td>000005_female_Asian_58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>female</td>\n",
       "      <td>Asian</td>\n",
       "      <td>59</td>\n",
       "      <td>000006_female_Asian_59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>6954</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006954_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2696</th>\n",
       "      <td>6955</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006955_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2697</th>\n",
       "      <td>6956</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006956_male_Asian_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2698</th>\n",
       "      <td>6957</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>20</td>\n",
       "      <td>006957_male_Asian_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>6959</td>\n",
       "      <td>male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>19</td>\n",
       "      <td>006959_male_Asian_19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2700 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  gender   race  age                    path\n",
       "0        1  female  Asian   45  000001_female_Asian_45\n",
       "1        2  female  Asian   52  000002_female_Asian_52\n",
       "2        4    male  Asian   54    000004_male_Asian_54\n",
       "3        5  female  Asian   58  000005_female_Asian_58\n",
       "4        6  female  Asian   59  000006_female_Asian_59\n",
       "...    ...     ...    ...  ...                     ...\n",
       "2695  6954    male  Asian   19    006954_male_Asian_19\n",
       "2696  6955    male  Asian   19    006955_male_Asian_19\n",
       "2697  6956    male  Asian   19    006956_male_Asian_19\n",
       "2698  6957    male  Asian   20    006957_male_Asian_20\n",
       "2699  6959    male  Asian   19    006959_male_Asian_19\n",
       "\n",
       "[2700 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./input/data/train/train.csv\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0655664c-e579-4350-aa9a-4b7365765d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_dir = './input/data/train/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be0f5a9b-cbb8-44a3-892e-1de5f2b7546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_box = pd.read_csv('./bounding_box.csv')\n",
    "bounding_box.set_index('img_paths', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968c29aa-6fc3-41ea-ad9e-8a5d1f24647d",
   "metadata": {},
   "source": [
    "# DataGeneration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd4e399-fca0-4a14-a16d-34f071264895",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31473cf4-3f69-4a1b-8a02-d7bce84edb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 마스크 여부, 성별, 나이를 mapping할 클래스를 생성합니다.\n",
    "\n",
    "class MaskLabels(int, Enum):\n",
    "    MASK = 0\n",
    "    INCORRECT = 1\n",
    "    NORMAL = 2\n",
    "\n",
    "\n",
    "class GenderLabels(int, Enum):\n",
    "    MALE = 0\n",
    "    FEMALE = 1\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(cls, value: str) -> int:\n",
    "        value = value.lower()\n",
    "        if value == \"male\":\n",
    "            return cls.MALE\n",
    "        elif value == \"female\":\n",
    "            return cls.FEMALE\n",
    "        else:\n",
    "            raise ValueError(f\"Gender value should be either 'male' or 'female', {value}\")\n",
    "\n",
    "\n",
    "class AgeLabels(int, Enum):\n",
    "    YOUNG = 0\n",
    "    MIDDLE = 1\n",
    "    OLD = 2\n",
    "\n",
    "    @classmethod\n",
    "    def from_number(cls, value: str) -> int:\n",
    "        try:\n",
    "            value = int(value)\n",
    "        except Exception:\n",
    "            raise ValueError(f\"Age value should be numeric, {value}\")\n",
    "\n",
    "        if value < 30:\n",
    "            return cls.YOUNG\n",
    "        elif value < 60:\n",
    "            return cls.MIDDLE\n",
    "        else:\n",
    "            return cls.OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38de2d00-ef9d-4330-99eb-e3ec8aa5b817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskBaseDataset(data.Dataset):\n",
    "    num_classes = 3 * 2 * 3\n",
    "\n",
    "    _file_names = {\n",
    "        \"mask1\": MaskLabels.MASK,\n",
    "        \"mask2\": MaskLabels.MASK,\n",
    "        \"mask3\": MaskLabels.MASK,\n",
    "        \"mask4\": MaskLabels.MASK,\n",
    "        \"mask5\": MaskLabels.MASK,\n",
    "        \"incorrect_mask\": MaskLabels.INCORRECT,\n",
    "        \"normal\": MaskLabels.NORMAL\n",
    "    }\n",
    "\n",
    "    image_paths = []\n",
    "    mask_labels = []\n",
    "    gender_labels = []\n",
    "    age_labels = []\n",
    "\n",
    "    def __init__(self, data_dir, mean=(0.56, 0.524, 0.501), std=(0.233, 0.243, 0.246), val_ratio=0.2):\n",
    "        self.data_dir = data_dir\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.val_ratio = val_ratio\n",
    "        self.indices = defaultdict(list)\n",
    "        \n",
    "        self.setup()\n",
    "        self.calc_statistics()\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def _split_profile(profiles, val_ratio):\n",
    "        total_len = len(profiles)\n",
    "        n_val = int(total_len * val_ratio)\n",
    "        total_indices = range(total_len)\n",
    "        val_indices = set(random.choices(total_indices, k=n_val))\n",
    "        train_indices = set(total_indices) - val_indices\n",
    "        \n",
    "        return {\"train\": train_indices, \"val\": val_indices}\n",
    "    \n",
    "    def setup(self):\n",
    "        profiles = os.listdir(self.data_dir)\n",
    "        profiles = [profile for profile in profiles if not profile.startswith(\".\")]\n",
    "        split_profiles = self._split_profile(profiles, self.val_ratio)\n",
    "\n",
    "        cnt = 0\n",
    "        for phase, indices in split_profiles.items():\n",
    "            for _idx in indices:\n",
    "                profile = profiles[_idx]\n",
    "                img_folder = os.path.join(self.data_dir, profile)\n",
    "                for file_name in os.listdir(img_folder):\n",
    "                    _file_name, ext = os.path.splitext(file_name)\n",
    "                    if _file_name not in self._file_names:  # \".\" 로 시작하는 파일 및 invalid 한 파일들은 무시합니다\n",
    "                        continue\n",
    "\n",
    "                    img_path = os.path.join(self.data_dir, profile, file_name)\n",
    "                    mask_label = self._file_names[_file_name]\n",
    "\n",
    "                    id, gender, race, age = profile.split(\"_\")\n",
    "                    if (27 < int(age) < 30) or (57 < int(age) < 60) :\n",
    "                        continue\n",
    "                    gender_label = GenderLabels.from_str(gender)\n",
    "                    age_label = AgeLabels.from_number(age)\n",
    "\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.mask_labels.append(mask_label)\n",
    "                    self.gender_labels.append(gender_label)\n",
    "                    self.age_labels.append(age_label)\n",
    "\n",
    "                    self.indices[phase].append(cnt)\n",
    "                    cnt += 1\n",
    "    \n",
    "    def split_dataset(self) -> List[Subset]:\n",
    "        return [Subset(self, indices) for phase, indices in self.indices.items()]\n",
    "    \n",
    "    def get_sampler(self, phase) :\n",
    "        _multi_class = []\n",
    "        for _idx in self.indices[phase]:\n",
    "            _multi_class.append(self.encode_multi_class(self.mask_labels[_idx], self.gender_labels[_idx], self.age_labels[_idx]))\n",
    "        \n",
    "        size = len(_multi_class)\n",
    "        class_counts = pd.DataFrame(_multi_class).value_counts().to_list()        \n",
    "        class_weights = [size / class_counts[i] for i in range(len(class_counts))] #클래스별 가중치 부여\n",
    "        weights = [class_weights[_multi_class[i]] for i in range(size)]            #해당 레이블마다의 가중치 비율\n",
    "        sampler = WeightedRandomSampler(torch.DoubleTensor(weights), size)\n",
    "    \n",
    "        return sampler\n",
    "\n",
    "    def calc_statistics(self):\n",
    "        has_statistics = self.mean is not None and self.std is not None\n",
    "        if not has_statistics:\n",
    "            print(\"[Warning] Calculating statistics... It can take a long time depending on your CPU machine\")\n",
    "            sums = []\n",
    "            squared = []\n",
    "            for image_path in self.image_paths[:3000]:\n",
    "                image = np.array(Image.open(image_path)).astype(np.int32)\n",
    "                sums.append(image.mean(axis=(0, 1)))\n",
    "                squared.append((image ** 2).mean(axis=(0, 1)))\n",
    "\n",
    "            self.mean = np.mean(sums, axis=0) / 255\n",
    "            self.std = (np.mean(squared, axis=0) - self.mean ** 2) ** 0.5 / 255\n",
    "\n",
    "    def set_train_transform(self, transform):\n",
    "        self.train_transform = transform\n",
    "        \n",
    "    def set_val_transform(self, transform):\n",
    "        self.val_transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path)\n",
    "        image = np.array(image)\n",
    "        # Face detect\n",
    "        if sum(bounding_box.loc['/opt/ml'+image_path[1:],]):\n",
    "            x_min, y_min, x_max, y_max = bounding_box.loc['/opt/ml'+image_path[1:],]\n",
    "            image = image[int(y_min):int(y_max), int(x_min):int(x_max)]\n",
    "        else:\n",
    "            image = Image.open(self.image_paths[index])\n",
    "            image = CenterCrop(300)(image)\n",
    "            \n",
    "        mask_label = self.get_mask_label(index)\n",
    "        gender_label = self.get_gender_label(index)\n",
    "        age_label = self.get_age_label(index)\n",
    "        multi_class_label = self.encode_multi_class(mask_label, gender_label, age_label)\n",
    "        \n",
    "        if index in self.indices[\"train\"]:\n",
    "            image_transform =  self.train_transform(image = np.array(image))[\"image\"]\n",
    "        else:\n",
    "            image_transform =  self.val_transform(image = np.array(image))[\"image\"]\n",
    "\n",
    "        return image_transform, multi_class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def get_mask_label(self, index) -> MaskLabels:\n",
    "        return self.mask_labels[index]\n",
    "\n",
    "    def get_gender_label(self, index) -> GenderLabels:\n",
    "        return self.gender_labels[index]\n",
    "\n",
    "    def get_age_label(self, index) -> AgeLabels:\n",
    "        return self.age_labels[index]\n",
    "\n",
    "    @staticmethod\n",
    "    def encode_multi_class(mask_label, gender_label, age_label) -> int:\n",
    "        return mask_label * 6 + gender_label * 3 + age_label\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_multi_class(multi_class_label) -> Tuple[MaskLabels, GenderLabels, AgeLabels]:\n",
    "        mask_label = (multi_class_label // 6) % 3\n",
    "        gender_label = (multi_class_label // 3) % 2\n",
    "        age_label = multi_class_label % 3\n",
    "        return mask_label, gender_label, age_label\n",
    "\n",
    "    @staticmethod\n",
    "    def denormalize_image(image, mean, std):\n",
    "        img_cp = image.copy()\n",
    "        img_cp *= std\n",
    "        img_cp += mean\n",
    "        img_cp *= 255.0\n",
    "        img_cp = np.clip(img_cp, 0, 255).astype(np.uint8)\n",
    "        return img_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "84900ee9-1439-43e3-abc6-9d8df64ea2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MaskBaseDataset(data_dir=train_img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "43450f07-fa28-4302-b792-6befd30235c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_val = int(len(dataset) * 0.3)\n",
    "n_train = len(dataset) - n_val\n",
    "train_dataset, val_dataset = data.random_split(dataset, [n_train, n_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f862a0ac-041b-4d93-979f-aa5001e8ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "        A.CLAHE(p=1, clip_limit=3.0),\n",
    "        A.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "        A.GaussNoise(p=1, var_limit=(0.0, 25)),\n",
    "        A.GridDistortion(p=1, distort_limit=(-0.02, 0.05)),\n",
    "        A.ISONoise(),\n",
    "        A.ElasticTransform(p=1, alpha=0.2, sigma=3, alpha_affine=2),\n",
    "        A.Resize(height=224, width=224),\n",
    "        A.CoarseDropout(p=1, max_holes=20, max_height=10, max_width=15, min_holes=1, min_height=5, min_width=5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Normalize(mean=(0.56, 0.524, 0.501), std=(0.233, 0.243, 0.246)),\n",
    "        ToTensorV2(),\n",
    "])\n",
    "    \n",
    "val_transform = A.Compose([\n",
    "        A.CLAHE(p=1, clip_limit=3.0),\n",
    "        A.Resize(height=224, width=224),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Normalize(mean=(0.56, 0.524, 0.501), std=(0.233, 0.243, 0.246)),\n",
    "        ToTensorV2(),\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b2e2ca7c-ac3a-4523-b5f2-eed9ec717d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.dataset.set_train_transform(train_transform)\n",
    "val_dataset.dataset.set_val_transform(val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "74eca32d-6800-4fa6-addf-9bfae2c80eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):\n",
    "    W = size[2] // 2  # 절반 위만 되도록 수정 (먀스크 윗부분)\n",
    "    H = size[3] \n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = np.int(W * cut_rat)\n",
    "    cut_h = np.int(H * cut_rat)\n",
    "\n",
    "    # uniform\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 5, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 5, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "    \n",
    "class CutMix(object):\n",
    "    def __init__(self, beta, cutmix_prob) -> None:\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.cutmix_prob = cutmix_prob\n",
    "        \n",
    "    def forward(self, images, labels):\n",
    "        lam = np.random.beta(self.beta, self.beta)\n",
    "        rand_index = torch.randperm(images.size()[0])\n",
    "        label_1 = labels\n",
    "        label_2 = labels[rand_index]\n",
    "        bbx1, bby1, bbx2, bby2 = rand_bbox(images.size(), lam)\n",
    "        images[:, :, bbx1:bbx2, bby1:bby2] = images[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "        \n",
    "        lam = 1 - ((bbx2-bbx1)*(bby2-bby1)/(images.size()[-1]*images.size()[-2]))\n",
    "        \n",
    "        return {'lam': lam, 'image': images, 'label_1': label_1, 'label_2': label_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc322944-24e2-49c0-865f-d5e7bdfab88b",
   "metadata": {},
   "source": [
    "## Aug 결과 예시 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "36598579-3479-4bf2-bdbd-a0ee66d818df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataloader은 데이터를 섞어주어야 합니다. (shuffle=True)\n",
    "train_loader = data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader = data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ed324b81-05e1-4527-9bee-9010d5317bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images shape: torch.Size([64, 3, 224, 224])\n",
      "labels shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(f'images shape: {images.shape}')\n",
    "print(f'labels shape: {labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4873db56-0bb8-430e-9f64-879d59707528",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutmix_prob = 0.5\n",
    "cutmix = CutMix(beta=1.0, cutmix_prob=cutmix_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "def0536f-e512-44c6-8b63-00265fcb6203",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = cutmix.forward(images, labels)['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7437dfc-5a2f-4192-ad00-a8ccd5aebacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Augmentation으로 이미지를 Normalize했기 때문에, 역으로 다시 Normalize\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-m / s for m, s in zip((0.56, 0.524, 0.501), (0.233, 0.243, 0.246))],\n",
    "    std=[1 / s for s in (0.233, 0.243, 0.246)]\n",
    ")\n",
    "\n",
    "n_rows, n_cols = 4, 3\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, sharex=True, sharey=True, figsize=(16, 24))\n",
    "for i in range(n_rows*n_cols):\n",
    "    axes[i%n_rows][i//(n_cols+1)].imshow(inv_normalize(images[i]).permute(1, 2, 0))\n",
    "    #axes[i%n_rows][i//(n_cols+1)].set_title(f'Label: {labels[i]}', color='r')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e6c1a-b556-4a79-83d3-43efe3744a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "920116b6fb34698f10a83cf3d191bb526e2b83df2edc9c5769a3bda3d85fd392"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
